import pathlib
from pathlib import Path
from typing import Any, List, Optional, Union

import torch.nn as nn
import torch
from transformers import BertModel, RobertaModel

from .model_config import PILinkModelConfig


class PILinkModel(nn.Module):
    """
    PyTorch module for the PI Link Model.

    Attributes:
        nlnl_model (RobertaModel): The underlying BERT model for natural language processing (NL-NL pair).
        linears (nn.Sequential): Sequential module for linear layers.
        sigmoid (nn.Sigmoid): Sigmoid activation function.

    Methods:
        from_trained_model: Load a trained model from a specified directory.
        forward: Forward pass for the model.

    """

    def __init__(
        self,
        config: PILinkModelConfig = PILinkModelConfig(),
        nlnl_model: Optional[RobertaModel] = None,
        nlpl_model: Optional[RobertaModel] = None
    ):
        super(PILinkModel, self).__init__()
        self.config: PILinkModelConfig = config

        self.nlnl_model: RobertaModel = RobertaModel(config.nlnl_model_config) if nlnl_model is None else nlnl_model
        # TODO: add nlpl model

        linear_block = lambda in_features, out_features: nn.Sequential(
            nn.Linear(in_features, out_features),
            nn.ReLU(),
        )
        linear_blocks = [
            linear_block(in_features, out_features)
            for in_features, out_features
            in zip([config.nlnl_model_config.hidden_size] + config.linear_sizes, config.linear_sizes)
        ]
        linears_but_last = nn.Sequential(*linear_blocks)

        self.linears = nn.Sequential(linears_but_last, nn.Linear(config.linear_sizes[-1], 1))
        self.sigmoid = nn.Sigmoid()

    @classmethod
    def from_trained_model(
        cls,
        model_name_or_path: Union[str, Path],
        device: Union[str, torch.device] = "cpu"
    ) -> 'PILinkModel':
        """
        Load a trained model from the specified directory.

        Args:
            model_name_or_path (Union[str, Path]): The path to the directory containing the model.
            device (Union[str, torch.device], optional): The device to load the model on. Defaults to "cpu".

        Returns:
            PILinkModel: The loaded trained model.

        Raises:
            ValueError: If the model directory or config file does not exist, or if the model file does not exist.
        """
        model_name_or_path = Path(model_name_or_path)
        model_dir_exist = Path.is_dir(model_name_or_path)
        if not model_dir_exist:
            raise ValueError(f"Model directory {model_name_or_path} does not exist.")

        # read config from json
        config_path = Path.joinpath(model_name_or_path, "config.json")
        config_exist = Path.is_file(config_path)
        if not config_exist:
            raise ValueError(f"Config file {config_path} does not exist.")
        config: PILinkModelConfig = PILinkModelConfig.from_json_file(config_path)

        # load model from config
        model = cls(config).to(device)

        # load model file
        model_path = Path.joinpath(model_name_or_path, "model.pt")
        model_exist = Path.is_file(model_path)
        if not model_exist:
            raise ValueError(f"Model file {model_path} does not exist.")
        model.load_state_dict(torch.load(model_path, map_location=device))

        return model
    
    @classmethod
    def from_scratch(
        cls,
        nlnl_model_name_or_path: Union[str, Path],
        nlpl_model_name_or_path: Union[str, Path],
        device: Union[str, torch.device] = "cpu"
    ) -> 'PILinkModel':
        """
        Create a new model from scratch. Initializes the NL-NL and NL-PL model from pretrained.

        Args:
            nlnl_model_name_or_path (Union[str, Path]): The name or path of the NL-NL model to load.
            nlpl_model_name_or_path (Union[str, Path]): The name or path of the NL-PL model to load.
            device (Union[str, torch.device], optional): The device to load the model on. Defaults to "cpu".
        
        Returns:
            PILinkModel: The new model.
        """
        
        nlnl_model: RobertaModel = RobertaModel.from_pretrained(nlnl_model_name_or_path)
        # nlpl_model = TODO
        config: PILinkModelConfig = PILinkModelConfig(
            nlnl_model_config=nlnl_model.config,
            # nlpl_model_config= nlpl_model.config
        )

        model = cls(config, nlnl_model=nlnl_model).to(device)
        return model

    def forward(self, nlnl_inputs):
        """
        Forward pass for the model.

        Args:
            nlnl_inputs (Dict): The natural language pair inputs to the model, generated by tokenizer. 
                                It is a dictionary with the following keys:
                                - input_ids (torch.Tensor): The input ids of the tokens.
                                - attention_mask (torch.Tensor): The attention mask of the tokens.
                                - token_type_ids (torch.Tensor): The token type ids of the tokens.
        Returns:
            torch.Tensor: The output tensor from the model.
        """
        nlnl_vec = self.nlnl_model(**nlnl_inputs).last_hidden_state
        nlnl_vec = nlnl_vec[:,0,:] # torch.FloatTensor of shape (batch_size, sequence_length, hidden_size)
        vec = nlnl_vec
        # vec = torch.cat((nlnl_vec, nlpl_vec), dim=1)
        out = self.linears(vec)
        out = self.sigmoid(out)
        return out
    